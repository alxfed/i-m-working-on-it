---
description: >-
  I found a wonderful book of Francois Chollet, the author of Keras, and it's
  exactly what I wanted to read at this point - a thoughtful overview of the
  subject with some extra details explained.
---

# Reading Chollet

    Since some point in the not so recent past I started reading books from the last chapter. In this book the last chapter is called: "Conclusions" \(Chapter 9\).

> ...anything that requires reasoning—like programming or applying the scientific method—long-term planning, and algorithmic data manipulation is out of reach for deep-learning models, no matter how much data you throw at them. Even learning a sorting algorithm with a deep neural network is tremendously difficult. This is because a deep-learning model is just a chain of simple, continuous geometric transformations mapping one vector space into another. All it can do is map one data manifold X into another manifold Y , assuming the existence of a _learnable_ continuous transform from X to Y . A deep-learning model can be interpreted as a kind of pro- gram; but, inversely, most programs can’t be expressed as deep-learning models—for most tasks, either there exists no corresponding deep-neural network that solves the task or, even if one exists, it may not be _learnable_: the corresponding geometric transform may be far too complex, or there may not be appropriate data available to learn it.

That is good enough. :\)

